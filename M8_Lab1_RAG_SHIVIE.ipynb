{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kiranrajkumar480/Gen_AI_Hackathon/blob/main/M8_Lab1_RAG_SHIVIE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![RAG Intro Lab](https://www.dropbox.com/scl/fi/hyyhk4rkslkgi6rd1ki5z/RAG_Intro_Lab.png?rlkey=31iuzmmvt9ta3xf649jma4y67&raw=1)\n"
      ],
      "metadata": {
        "id": "F8wzOI-QD1d9"
      },
      "id": "F8wzOI-QD1d9"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e0f1adbd",
      "metadata": {
        "id": "e0f1adbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e2ecf74-c41c-4a2d-bab1-61b25d11b2a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/2.5 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m2.3/2.5 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.2/65.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.1/438.1 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.0/363.0 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.4/118.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m100.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.2/304.2 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.5/112.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.1/526.1 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.6/167.6 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.8/195.8 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# 📦 Installing Required Libraries for LangChain RAG Lab (Quiet Mode)\n",
        "# ==================================================\n",
        "\n",
        "# --- Core LangChain and OpenAI Integration ---\n",
        "!pip install -q --upgrade langchain langchain-community langchain-openai\n",
        "\n",
        "# --- OpenAI SDK ---\n",
        "# 'openai': Required to access GPT-3.5/4 and manage API keys, works with both LangChain and direct calls\n",
        "!pip install -q --upgrade openai\n",
        "\n",
        "# --- Vector Databases for Retrieval (RAG) ---\n",
        "# 'faiss-cpu': Facebook's FAISS for fast vector search (in-memory or persistent)\n",
        "# 'chromadb': Lightweight vector database, ideal for local demos and quick setup\n",
        "!pip install -q --upgrade faiss-cpu chromadb\n",
        "\n",
        "# --- Tokenization and Unstructured Data Support ---\n",
        "# 'tiktoken': Fast, efficient tokenizer (used with OpenAI, supports counting tokens accurately)\n",
        "# 'unstructured': Loads/cleans data from PDFs, DOCX, HTML, email, etc. for use in retrieval pipelines\n",
        "# 'unstructured[pdf]': Adds PDF parsing support (using pdfminer, pypdf, etc.)\n",
        "# 'pypdf', 'pdfminer.six': Popular PDF parsing backends, required for some document loaders\n",
        "!pip install -q --upgrade tiktoken unstructured \"unstructured[pdf]\" pypdf pdfminer.six\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9f6983d2",
      "metadata": {
        "id": "9f6983d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48253fb2-0a79-4b63-b132-457482559519"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All libraries imported and categorized successfully!\n"
          ]
        }
      ],
      "source": [
        "# 📚 LangChain RAG Lab: Library Imports & Setup\n",
        "# ====================================================\n",
        "# ✅ This cell handles all required imports, grouped by category for clarity.\n",
        "\n",
        "# 🧱 System & Environment Setup\n",
        "import os  # Environment variable access\n",
        "import requests  # For fetching remote resources (e.g., PDFs, data files)\n",
        "from google.colab import userdata  # Accessing Colab-specific secure data\n",
        "\n",
        "# 🧪 Jupyter & Colab Display Utilities\n",
        "import ipywidgets as widgets  # Interactive widgets\n",
        "from IPython.display import clear_output, display, HTML  # Display controls\n",
        "\n",
        "# 🔑 OpenAI API\n",
        "import openai  # Optional: raw API access (not required for LangChain unless custom use)\n",
        "\n",
        "# 🧠 LangChain Core Modules\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings  # LLM + Embeddings via OpenAI\n",
        "from langchain_core.prompts import PromptTemplate  # Structured prompt templates\n",
        "from langchain.memory import ConversationBufferMemory  # For chat history memory\n",
        "\n",
        "\n",
        "# ✅ Confirmation\n",
        "print(\"✅ All libraries imported and categorized successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "<style>\n",
        "body {\n",
        "    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;\n",
        "    line-height: 1.4;\n",
        "    color: #1a1a1a;\n",
        "    max-width: 750px;\n",
        "    margin: 0 auto;\n",
        "    padding: 8px;\n",
        "    font-size: 14px;\n",
        "}\n",
        "\n",
        ".section-header {\n",
        "    background-color: #e8f0fe;\n",
        "    padding: 12px;\n",
        "    margin: 12px 0;\n",
        "    border-radius: 4px;\n",
        "    border-left: 3px solid #1a73e8;\n",
        "}\n",
        "\n",
        ".description-box {\n",
        "    background-color: #f8f9fa;\n",
        "    padding: 14px;\n",
        "    margin: 12px 0;\n",
        "    border-radius: 4px;\n",
        "    border: 1px solid #e0e0e0;\n",
        "}\n",
        "\n",
        "h2 {\n",
        "    color: #1a73e8;\n",
        "    font-size: 1.15em;\n",
        "    margin: 0;\n",
        "}\n",
        "\n",
        ".code-note {\n",
        "    background-color: #fff;\n",
        "    padding: 10px;\n",
        "    margin: 10px 0;\n",
        "    border-radius: 4px;\n",
        "    border: 1px solid #dadce0;\n",
        "    font-size: 0.9em;\n",
        "}\n",
        "\n",
        ".highlight {\n",
        "    color: #1a73e8;\n",
        "    font-weight: 600;\n",
        "}\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "<div class=\"section-header\">\n",
        "    <h2>🖨️ Pretty Print Function</h2>\n",
        "</div>\n",
        "\n",
        "<div class=\"description-box\">\n",
        "    <p style=\"margin: 0 0 8px 0;\">The <span class=\"highlight\">pretty_print()</span> function enhances output readability by transforming standard text into styled HTML blocks. This utility function replaces basic print statements with visually appealing formatted displays that improve the user experience when viewing model responses and system outputs.</p>\n",
        "    \n",
        "    <p style=\"margin: 8px 0 0 0;\">Key features include automatic detection and formatting of bulleted lists, proper line break handling, and consistent visual styling that matches the laboratory's design theme. The function accepts two parameters: the text content to display and an optional title that appears as a header above the formatted output.</p>\n",
        "</div>\n",
        "\n",
        "<div class=\"code-note\">\n",
        "    <strong>Usage:</strong> Replace standard <code>print()</code> statements with <code>pretty_print()</code> throughout your notebook to maintain consistent, professional output formatting.\n",
        "</div>\n",
        "\n",
        "</body>\n",
        "</html>"
      ],
      "metadata": {
        "id": "5wu-5wP8z3h8"
      },
      "id": "5wu-5wP8z3h8"
    },
    {
      "cell_type": "code",
      "source": [
        "# 🖨️ pretty_print(): Reusable HTML display function for model outputs\n",
        "def pretty_print(text, title=\"🤖 Model Response\"):\n",
        "    \"\"\"\n",
        "    Display model response in styled HTML block.\n",
        "    Handles bulleted lists and line breaks.\n",
        "    \"\"\"\n",
        "    lines = text.strip().split('\\n')\n",
        "    is_bulleted = all(line.strip().startswith((\"-\", \"•\", \"*\")) for line in lines if line.strip())\n",
        "\n",
        "    if is_bulleted:\n",
        "        list_items = ''.join(f\"<li>{line.lstrip('-•* ').strip()}</li>\" for line in lines if line.strip())\n",
        "        content_html = f\"<ul style='margin-top: 6px;'>{list_items}</ul>\"\n",
        "    else:\n",
        "        content_html = text.replace(\"\\n\", \"<br>\")  # fallback for plain lines\n",
        "\n",
        "    display(HTML(f\"\"\"\n",
        "    <div style=\"background-color:#f8f9fc; border-left:5px solid #4285f4;\n",
        "                padding:16px; margin-top:16px; font-family:'Segoe UI', sans-serif;\n",
        "                color:#202124; line-height:1.6;\">\n",
        "      <strong>{title}</strong><br><br>\n",
        "      {content_html}\n",
        "    </div>\n",
        "    \"\"\"))"
      ],
      "metadata": {
        "id": "gJZi1HGbz-XD"
      },
      "id": "gJZi1HGbz-XD",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "<style>\n",
        "body {\n",
        "    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;\n",
        "    line-height: 1.4;\n",
        "    color: #1a1a1a;\n",
        "    max-width: 750px;\n",
        "    margin: 0 auto;\n",
        "    padding: 8px;\n",
        "    font-size: 14px;\n",
        "}\n",
        "\n",
        ".section-header {\n",
        "    background-color: #e8f0fe;\n",
        "    padding: 12px;\n",
        "    margin: 12px 0;\n",
        "    border-radius: 4px;\n",
        "    border-left: 3px solid #1a73e8;\n",
        "}\n",
        "\n",
        "h2 {\n",
        "    color: #1a73e8;\n",
        "    font-size: 1.15em;\n",
        "    margin: 0;\n",
        "}\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "<div class=\"section-header\">\n",
        "    <h2>🔑 OpenAI API Key Setup from Colab Secrets</h2>\n",
        "</div>\n",
        "\n",
        "</body>\n",
        "</html>"
      ],
      "metadata": {
        "id": "gGqlpWgd0LKn"
      },
      "id": "gGqlpWgd0LKn"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2d4e47a7",
      "metadata": {
        "id": "2d4e47a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7e9831c-e42f-459d-cf54-ac6a172a421d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔐 OpenAI API Key successfully set from Colab Secrets!\n"
          ]
        }
      ],
      "source": [
        "# ==================================================\n",
        "# 🔑 OpenAI API Key Setup from Colab Secrets\n",
        "# ==================================================\n",
        "\n",
        "import os\n",
        "\n",
        "try:\n",
        "    from google.colab import userdata  # Colab-specific secure storage\n",
        "    openai_key = userdata.get('openAI_apikey')  # Must be pre-stored via UI\n",
        "\n",
        "    if openai_key:\n",
        "        os.environ[\"OPENAI_API_KEY\"] = openai_key  # ✅ Correct key name\n",
        "        print(\"🔐 OpenAI API Key successfully set from Colab Secrets!\")\n",
        "    else:\n",
        "        print(\"⚠️ OpenAI API Key not found in Colab Secrets. Please add it via Colab ➤ More ➤ Secrets.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"🚫 Error retrieving OpenAI API Key: {e}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "<style>\n",
        "body {\n",
        "    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;\n",
        "    line-height: 1.4;\n",
        "    color: #1a1a1a;\n",
        "    max-width: 750px;\n",
        "    margin: 0 auto;\n",
        "    padding: 8px;\n",
        "    font-size: 14px;\n",
        "}\n",
        "\n",
        ".section-header {\n",
        "    background-color: #e8f0fe;\n",
        "    padding: 12px;\n",
        "    margin: 12px 0;\n",
        "    border-radius: 4px;\n",
        "    border-left: 3px solid #1a73e8;\n",
        "}\n",
        "\n",
        "h2 {\n",
        "    color: #1a73e8;\n",
        "    font-size: 1.15em;\n",
        "    margin: 0;\n",
        "}\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "<div class=\"section-header\">\n",
        "    <h2>🔷 Part 1: Non-RAG Model Implementation</h2>\n",
        "</div>\n",
        "\n",
        "</body>\n",
        "</html>"
      ],
      "metadata": {
        "id": "O-6iyAWy1t02"
      },
      "id": "O-6iyAWy1t02"
    },
    {
      "cell_type": "code",
      "source": [
        "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "# SIMPLE LANGCHAIN LLM QUERY - NO RAG COMPONENTS\n",
        "# Direct language model query using LangChain without document retrieval\n",
        "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "# Initialize language model\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=500\n",
        ")\n",
        "\n",
        "# Execute query\n",
        "query = \"What do I learn in the GenAI course in 3 bullets, software, application. Also who is the prof? any hints for me to gain a good grade?\"\n",
        "response = llm.invoke(query)\n",
        "\n",
        "# Display result\n",
        "pretty_print(response.content, title=\"🎯 Direct LLM Response\")"
      ],
      "metadata": {
        "id": "jAN-AfeL_cvQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "eec37dcc-31a1-4f66-84ec-ded8c09877c0"
      },
      "id": "jAN-AfeL_cvQ",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"background-color:#f8f9fc; border-left:5px solid #4285f4;\n",
              "                padding:16px; margin-top:16px; font-family:'Segoe UI', sans-serif;\n",
              "                color:#202124; line-height:1.6;\">\n",
              "      <strong>🎯 Direct LLM Response</strong><br><br>\n",
              "      - In the GenAI course, you will learn about various aspects of artificial intelligence, including machine learning algorithms, neural networks, and genetic algorithms.<br>- You will also learn how to apply these concepts to real-world problems, such as image recognition, natural language processing, and autonomous driving.<br>- The professor for the course is Dr. John Smith, who is an expert in the field of artificial intelligence and has published numerous papers on the subject.<br><br>To gain a good grade in the course, make sure to attend all lectures, participate actively in class discussions, complete all assignments on time, and study regularly. Additionally, seek help from the professor or teaching assistants if you have any questions or need clarification on any topic.\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "<style>\n",
        "body {\n",
        "    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;\n",
        "    line-height: 1.4;\n",
        "    color: #1a1a1a;\n",
        "    max-width: 750px;\n",
        "    margin: 0 auto;\n",
        "    padding: 8px;\n",
        "    font-size: 14px;\n",
        "}\n",
        "\n",
        ".section-header {\n",
        "    background-color: #e8f0fe;\n",
        "    padding: 12px;\n",
        "    margin: 12px 0;\n",
        "    border-radius: 4px;\n",
        "    border-left: 3px solid #1a73e8;\n",
        "}\n",
        "\n",
        ".explanation-box {\n",
        "    background-color: #f0f6ff;\n",
        "    border-left: 3px solid #1a73e8;\n",
        "    padding: 16px;\n",
        "    margin: 16px 0;\n",
        "    border-radius: 4px;\n",
        "}\n",
        "\n",
        ".process-diagram {\n",
        "    background: white;\n",
        "    border: 1px solid #dadce0;\n",
        "    border-radius: 8px;\n",
        "    padding: 20px;\n",
        "    margin: 16px 0;\n",
        "}\n",
        "\n",
        ".step-container {\n",
        "    display: grid;\n",
        "    grid-template-columns: repeat(4, 1fr);\n",
        "    gap: 15px;\n",
        "    margin: 20px 0;\n",
        "}\n",
        "\n",
        ".step-card {\n",
        "    background: #f8f9fa;\n",
        "    border-radius: 8px;\n",
        "    padding: 15px;\n",
        "    text-align: center;\n",
        "    border-top: 3px solid #1a73e8;\n",
        "    position: relative;\n",
        "}\n",
        "\n",
        ".step-number {\n",
        "    background: #1a73e8;\n",
        "    color: white;\n",
        "    width: 28px;\n",
        "    height: 28px;\n",
        "    border-radius: 50%;\n",
        "    display: flex;\n",
        "    align-items: center;\n",
        "    justify-content: center;\n",
        "    font-weight: bold;\n",
        "    margin: 0 auto 10px;\n",
        "}\n",
        "\n",
        ".step-arrow {\n",
        "    position: absolute;\n",
        "    right: -10px;\n",
        "    top: 50%;\n",
        "    transform: translateY(-50%);\n",
        "    color: #1a73e8;\n",
        "    font-size: 20px;\n",
        "}\n",
        "\n",
        ".technology-grid {\n",
        "    display: grid;\n",
        "    grid-template-columns: repeat(2, 1fr);\n",
        "    gap: 12px;\n",
        "    margin: 16px 0;\n",
        "}\n",
        "\n",
        ".tech-card {\n",
        "    background: white;\n",
        "    border: 1px solid #e0e0e0;\n",
        "    border-radius: 6px;\n",
        "    padding: 12px;\n",
        "}\n",
        "\n",
        "h2 {\n",
        "    color: #1a73e8;\n",
        "    font-size: 1.15em;\n",
        "    margin: 0;\n",
        "}\n",
        "\n",
        "h3 {\n",
        "    color: #1a73e8;\n",
        "    font-size: 1em;\n",
        "    margin: 8px 0;\n",
        "}\n",
        "\n",
        ".highlight {\n",
        "    color: #1a73e8;\n",
        "    font-weight: 600;\n",
        "}\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "<div class=\"section-header\">\n",
        "    <h2>🔷 Part 2: RAG Model Implementation</h2>\n",
        "</div>\n",
        "\n",
        "<div class=\"explanation-box\">\n",
        "    <h3>Understanding the RAG Architecture</h3>\n",
        "    <p>The Retrieval-Augmented Generation system enhances language model responses by incorporating document-specific context. Unlike standard LLMs that rely solely on training data, RAG systems actively search through your documents to find relevant information before generating responses.</p>\n",
        "</div>\n",
        "\n",
        "<div class=\"chart-container\">\n",
        "    <img src=\"https://www.dropbox.com/scl/fi/w7w1hfzgzdu46ydv9on00/RAG_Structure.png?rlkey=ef8r6nfdtbg3zvw90900w6rt8&dl=1\" alt=\"RAG Architecture Overview\" style=\"width: 70%; max-width: 70%;\">\n",
        "</div>\n",
        "\n",
        "</body>\n",
        "</html>"
      ],
      "metadata": {
        "id": "_PRn2D8jvdfc"
      },
      "id": "_PRn2D8jvdfc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<div class=\"explanation-box\" style=\"background-color: #f8f9fa;\">\n",
        "    <h3>How Retrieval Works</h3>\n",
        "    <p>When a user submits a query, the system:</p>\n",
        "    <ol style=\"margin: 8px 0 0 20px; padding: 0;\">\n",
        "        <li>Converts the query into an embedding vector using the same model</li>\n",
        "        <li>Searches the FAISS index for the k most similar document chunks</li>\n",
        "        <li>Passes these relevant chunks as context to the language model</li>\n",
        "        <li>Generates a response grounded in the retrieved information</li>\n",
        "    </ol>\n",
        "    <p style=\"margin-top: 12px;\">This approach ensures responses are based on your specific documents rather than general knowledge, significantly improving accuracy and relevance.</p>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "D0wL3XSYGSQg"
      },
      "id": "D0wL3XSYGSQg"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "<style>\n",
        "body {\n",
        "    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;\n",
        "    line-height: 1.4;\n",
        "    color: #1a1a1a;\n",
        "    max-width: 750px;\n",
        "    margin: 0 auto;\n",
        "    padding: 8px;\n",
        "    font-size: 14px;\n",
        "}\n",
        "\n",
        ".task-header {\n",
        "    background-color: #e8f0fe;\n",
        "    padding: 12px 14px;\n",
        "    margin: 10px 0;\n",
        "    border-radius: 4px;\n",
        "    border-left: 3px solid #1a73e8;\n",
        "}\n",
        "\n",
        ".task-details {\n",
        "    background-color: #f8f9fa;\n",
        "    padding: 12px;\n",
        "    margin: 8px 0;\n",
        "    border-radius: 4px;\n",
        "    border: 1px solid #e0e0e0;\n",
        "    font-size: 0.9em;\n",
        "}\n",
        "\n",
        "h3 {\n",
        "    color: #1a73e8;\n",
        "    font-size: 1.05em;\n",
        "    margin: 0 0 8px 0;\n",
        "}\n",
        "\n",
        ".process-list {\n",
        "    margin: 8px 0 0 0;\n",
        "    padding-left: 20px;\n",
        "}\n",
        "\n",
        ".process-list li {\n",
        "    margin: 4px 0;\n",
        "    color: #444;\n",
        "}\n",
        "\n",
        ".highlight {\n",
        "    color: #1a73e8;\n",
        "    font-weight: 600;\n",
        "}\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "<div class=\"task-header\">\n",
        "    <h3>📥 Task 1: Document Loading</h3>\n",
        "    <div class=\"task-details\">\n",
        "        <p style=\"margin: 0 0 8px 0;\">This task retrieves the course syllabus PDF from Dropbox and prepares it for RAG processing. The document undergoes three key transformations to enable efficient semantic search:</p>\n",
        "        <ul class=\"process-list\">\n",
        "            <li><span class=\"highlight\">Download:</span> Fetch the PDF file using the provided Dropbox URL</li>\n",
        "            <li><span class=\"highlight\">Load:</span> Extract text content from all pages using PyPDFLoader</li>\n",
        "            <li><span class=\"highlight\">Chunk:</span> Split the document into 1000-character segments with 200-character overlap to preserve context boundaries</li>\n",
        "        </ul>\n",
        "        <p style=\"margin: 8px 0 0 0;\">The chunking strategy ensures that related information remains together while creating appropriately sized segments for embedding generation. The overlap prevents important context from being lost at chunk boundaries.</p>\n",
        "    </div>\n",
        "</div>\n",
        "\n",
        "</body>\n",
        "</html>"
      ],
      "metadata": {
        "id": "WbwXKoqixNYb"
      },
      "id": "WbwXKoqixNYb"
    },
    {
      "cell_type": "code",
      "source": [
        "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "#>> DOCUMENT LOADING AND PROCESSING\n",
        "# This cell downloads the PDF from Dropbox, loads it into memory,\n",
        "# and splits it into manageable chunks for vector search\n",
        "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "# 📦 Document Loaders\n",
        "from langchain.document_loaders import PyPDFLoader  # Load content from PDFs\n",
        "from langchain_community.document_loaders import TextLoader  # Load plain text files\n",
        "\n",
        "# ✂️ Text Processing & Chunking\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter # Import the text splitter here\n",
        "\n",
        "\n",
        "# Download PDF from Dropbox\n",
        "dropbox_url = \"https://www.dropbox.com/scl/fi/zedqrdppb6et1sm3s09r6/IE_5250_Applied_Generative_AI-2025.pdf?rlkey=tn3130kcd5o03twalmydn8t6p&e=1&dl=1\"\n",
        "pdf_path = \"/content/document.pdf\"\n",
        "\n",
        "response = requests.get(dropbox_url)\n",
        "with open(pdf_path, \"wb\") as file:\n",
        "    file.write(response.content)\n",
        "\n",
        "# Load and process the PDF\n",
        "loader = PyPDFLoader(pdf_path)\n",
        "documents = loader.load()\n",
        "\n",
        "# Split into chunks for better retrieval accuracy\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200,\n",
        "    length_function=len,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
        ")\n",
        "docs = text_splitter.split_documents(documents)\n",
        "\n",
        "pretty_print(f\"PDF successfully downloaded and processed\\n{len(documents)} pages converted into {len(docs)} searchable chunks\",\n",
        "             title=\"📥 Document Loading Complete\")"
      ],
      "metadata": {
        "id": "TE5LmmBV2nfv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "outputId": "46aca2a9-ea65-4e4c-d338-c3c3312ba9fe"
      },
      "id": "TE5LmmBV2nfv",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"background-color:#f8f9fc; border-left:5px solid #4285f4;\n",
              "                padding:16px; margin-top:16px; font-family:'Segoe UI', sans-serif;\n",
              "                color:#202124; line-height:1.6;\">\n",
              "      <strong>📥 Document Loading Complete</strong><br><br>\n",
              "      PDF successfully downloaded and processed<br>5 pages converted into 16 searchable chunks\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "<style>\n",
        "body {\n",
        "    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;\n",
        "    line-height: 1.4;\n",
        "    color: #1a1a1a;\n",
        "    max-width: 750px;\n",
        "    margin: 0 auto;\n",
        "    padding: 8px;\n",
        "    font-size: 14px;\n",
        "}\n",
        "\n",
        ".task-header {\n",
        "    background-color: #e8f0fe;\n",
        "    padding: 10px 12px;\n",
        "    margin: 10px 0;\n",
        "    border-radius: 4px;\n",
        "    border-left: 3px solid #1a73e8;\n",
        "}\n",
        "\n",
        "h3 {\n",
        "    color: #1a73e8;\n",
        "    font-size: 1.05em;\n",
        "    margin: 0;\n",
        "}\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "<!-- Task 2 Header -->\n",
        "<div class=\"task-header\">\n",
        "    <h3>🧮 Task 2: Embedding Generation & Vector Store Creation</h3>\n",
        "</div>\n",
        "\n",
        "\n",
        "</body>\n",
        "</html>"
      ],
      "metadata": {
        "id": "xdxwNlK7yZcF"
      },
      "id": "xdxwNlK7yZcF"
    },
    {
      "cell_type": "code",
      "source": [
        "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "#>> EMBEDDING GENERATION AND VECTOR STORE CREATION\n",
        "# This cell converts text chunks into vector embeddings using OpenAI's\n",
        "# model and stores them in a FAISS index for fast similarity search\n",
        "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "# ✂️ Text Processing & Chunking\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter  # Split text into chunks\n",
        "\n",
        "# 📚 Vector Store & Embeddings\n",
        "from langchain.vectorstores import FAISS  # FAISS for fast vector search\n",
        "\n",
        "# Initialize embedding model\n",
        "embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
        "\n",
        "# Create FAISS vector store\n",
        "vector_db = FAISS.from_documents(docs, embedding_model)\n",
        "\n",
        "# Prepare sample chunks display\n",
        "sample_chunks = []\n",
        "for i in range(min(3, len(docs))):\n",
        "    chunk_preview = docs[i].page_content[:150].strip()\n",
        "    sample_chunks.append(f\"• Chunk {i+1}: {chunk_preview}...\")\n",
        "\n",
        "sample_text = f\"Embeddings successfully created for {len(docs)} chunks\\n\\nSample chunks:\\n\" + \"\\n\".join(sample_chunks)\n",
        "pretty_print(sample_text, title=\"🧠 Embedding Generation Complete\")\n"
      ],
      "metadata": {
        "id": "va7gBXMBxSUJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "outputId": "c9942a2b-2485-4161-e9e1-45ee29102fcb"
      },
      "id": "va7gBXMBxSUJ",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"background-color:#f8f9fc; border-left:5px solid #4285f4;\n",
              "                padding:16px; margin-top:16px; font-family:'Segoe UI', sans-serif;\n",
              "                color:#202124; line-height:1.6;\">\n",
              "      <strong>🧠 Embedding Generation Complete</strong><br><br>\n",
              "      Embeddings successfully created for 16 chunks<br><br>Sample chunks:<br>• Chunk 1: IE 5250: Applied Generative AI<br>Prof. Mohammad Dehghani<br>\"Prioritize utilizing readily available tools and frameworks instead of developing AI applicati...<br>• Chunk 2: Course Overview<br>Examines how Generative AI (GenAI) and autonomous Agentic AI systems leverage<br>large language models (LLMs) to extract insights, genera...<br>• Chunk 3: tical implementation of GenAI.<br>Note: There are no prerequisites for this course, although familiarity with cod-<br>ing in Python is a plus.<br>Course Object...\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "<style>\n",
        "body {\n",
        "    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;\n",
        "    line-height: 1.4;\n",
        "    color: #1a1a1a;\n",
        "    max-width: 750px;\n",
        "    margin: 0 auto;\n",
        "    padding: 8px;\n",
        "    font-size: 14px;\n",
        "}\n",
        "\n",
        ".task-header {\n",
        "    background-color: #e8f0fe;\n",
        "    padding: 10px 12px;\n",
        "    margin: 10px 0;\n",
        "    border-radius: 4px;\n",
        "    border-left: 3px solid #1a73e8;\n",
        "}\n",
        "\n",
        "h3 {\n",
        "    color: #1a73e8;\n",
        "    font-size: 1.05em;\n",
        "    margin: 0;\n",
        "}\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "\n",
        "<!-- Task 3 Header -->\n",
        "<div class=\"task-header\">\n",
        "    <h3>🔍 Task 3: Query and Retrieval</h3>\n",
        "</div>\n",
        "\n",
        "</body>\n",
        "</html>"
      ],
      "metadata": {
        "id": "nEKNYkMDyesF"
      },
      "id": "nEKNYkMDyesF"
    },
    {
      "cell_type": "code",
      "source": [
        "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "#>> RETRIEVAL AND QUESTION ANSWERING\n",
        "# This cell sets up the RAG chain, performs retrieval testing,\n",
        "# and executes queries against the document\n",
        "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "# 🔁 Retrieval-Augmented Generation (RAG)\n",
        "from langchain.chains import RetrievalQA  # Combine retriever + LLM into a QA system\n",
        "\n",
        "# Initialize language model\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "# Create retriever\n",
        "retriever = vector_db.as_retriever(search_kwargs={\"k\": 4})\n",
        "\n",
        "# Test retrieval functionality\n",
        "test_docs = retriever.get_relevant_documents(\"document\")\n",
        "retrieval_status = f\"Retrieval system operational: {len(test_docs)} documents successfully retrieved\"\n",
        "\n",
        "# Build RAG chain\n",
        "rag_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True\n",
        ")\n",
        "\n",
        "# Execute query\n",
        "query = \"What do I learn in the GenAI course in 3 bullets, software, appliciaon. Also who is the prof? any hitns for me to gain a good grade?\"\n",
        "result = rag_chain({\"query\": query})\n",
        "\n",
        "# Format the complete response\n",
        "query_result_text = f\"{retrieval_status}\\n\\nQuery: {query}\\n\\nAnswer:\\n{result['result']}\\n\\nSource Documents Used: {len(result['source_documents'])}\"\n",
        "pretty_print(query_result_text, title=\"🔍 RAG Query Results\")"
      ],
      "metadata": {
        "id": "Aa0-P4bq8ehZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "outputId": "303bae87-10ca-44ec-e1b0-585fd86efe74"
      },
      "id": "Aa0-P4bq8ehZ",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-16664b1977f5>:17: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  test_docs = retriever.get_relevant_documents(\"document\")\n",
            "<ipython-input-12-16664b1977f5>:30: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  result = rag_chain({\"query\": query})\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"background-color:#f8f9fc; border-left:5px solid #4285f4;\n",
              "                padding:16px; margin-top:16px; font-family:'Segoe UI', sans-serif;\n",
              "                color:#202124; line-height:1.6;\">\n",
              "      <strong>🔍 RAG Query Results</strong><br><br>\n",
              "      Retrieval system operational: 4 documents successfully retrieved<br><br>Query: What do I learn in the GenAI course in 3 bullets, software, appliciaon. Also who is the prof? any hitns for me to gain a good grade?<br><br>Answer:<br>In the GenAI course (IE 5250: Applied Generative AI) taught by Prof. Mohammad Dehghani, you will learn:<br><br>1. How to apply GenAI for data analytics in real-world scenarios like exploring the relationship between presidential elections and Bitcoin prices.<br>2. How to leverage GenAI for predictive modeling and decision-making in areas like supply chain optimization and health transitions.<br>3. How to develop AI-enabled solutions for classical engineering problems such as scheduling and resource planning.<br><br>To excel in the course and gain a good grade, prioritize utilizing the essential tools and platforms mentioned in the course outline, actively participate in class activities, engage in teamwork during projects and hackathons, and ensure you have a good grasp of Python basics for effective completion of programming tasks.<br><br>Source Documents Used: 4\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color: #f0f6ff; border-left: 3px solid #1a73e8; padding: 16px; margin: 12px 0; border-radius: 4px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; color: #1a1a1a; font-size: 14px; line-height: 1.4; max-width: 750px;\">\n",
        "\n",
        "<h2 style=\"color: #1a73e8; font-size: 1.15em; font-weight: 600; margin: 0 0 12px 0;\">🔷 Vector Database Alternatives to FAISS</h2>\n",
        "\n",
        "<p>While FAISS excels at similarity search, several alternatives offer unique features for RAG applications. Each database addresses different needs regarding ease of use, scalability, and deployment options.</p>\n",
        "\n",
        "<ul style=\"margin: 12px 0; padding-left: 20px;\">\n",
        "  <li style=\"margin: 10px 0;\">\n",
        "    <a href=\"https://www.trychroma.com/\" target=\"_blank\" style=\"color: #1a73e8; font-weight: 600; text-decoration: none;\">ChromaDB</a> – Open-source embedding DB with simple API design and LangChain support.  \n",
        "    <a href=\"https://docs.trychroma.com/\" target=\"_blank\" style=\"color: #1a73e8; text-decoration: none;\">Learn more →</a>\n",
        "  </li>\n",
        "  \n",
        "  <li style=\"margin: 10px 0;\">\n",
        "    <a href=\"https://www.pinecone.io/\" target=\"_blank\" style=\"color: #1a73e8; font-weight: 600; text-decoration: none;\">Pinecone</a> – Fully managed vector DB, ideal for production-scale with zero infra hassle.  \n",
        "    <a href=\"https://docs.pinecone.io/\" target=\"_blank\" style=\"color: #1a73e8; text-decoration: none;\">Learn more →</a>\n",
        "  </li>\n",
        "\n",
        "  <li style=\"margin: 10px 0;\">\n",
        "    <a href=\"https://weaviate.io/\" target=\"_blank\" style=\"color: #1a73e8; font-weight: 600; text-decoration: none;\">Weaviate</a> – Combines vector + structured search with GraphQL and ML modules.  \n",
        "    <a href=\"https://weaviate.io/developers/weaviate\" target=\"_blank\" style=\"color: #1a73e8; text-decoration: none;\">Learn more →</a>\n",
        "  </li>\n",
        "\n",
        "  <li style=\"margin: 10px 0;\">\n",
        "    <a href=\"https://qdrant.tech/\" target=\"_blank\" style=\"color: #1a73e8; font-weight: 600; text-decoration: none;\">Qdrant</a> – Rust-based engine offering fast vector search and advanced filtering.  \n",
        "    <a href=\"https://qdrant.tech/documentation/\" target=\"_blank\" style=\"color: #1a73e8; text-decoration: none;\">Learn more →</a>\n",
        "  </li>\n",
        "</ul>\n",
        "\n",
        "<div style=\"margin-top: 14px; padding-top: 12px; border-top: 1px solid #dadce0; font-size: 0.9em; color: #555;\">\n",
        "  <strong>Selection Guide:</strong> Use <b>ChromaDB</b> for quick dev, <b>Pinecone</b> for managed infra, <b>Weaviate</b> for hybrid search, or <b>Qdrant</b> for speed.  \n",
        "  <i>FAISS</i> is still great for offline and lightweight use.\n",
        "</div>\n",
        "\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "i6sGnvE9AH3_"
      },
      "id": "i6sGnvE9AH3_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "<style>\n",
        "body {\n",
        "    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;\n",
        "    line-height: 1.4;\n",
        "    color: #1a1a1a;\n",
        "    max-width: 750px;\n",
        "    margin: 0 auto;\n",
        "    padding: 8px;\n",
        "    font-size: 14px;\n",
        "}\n",
        "\n",
        ".section-header {\n",
        "    background-color: #e8f0fe;\n",
        "    padding: 12px;\n",
        "    margin: 12px 0;\n",
        "    border-radius: 4px;\n",
        "    border-left: 3px solid #1a73e8;\n",
        "}\n",
        "\n",
        ".intro-box {\n",
        "    background-color: #f0f6ff;\n",
        "    border-left: 3px solid #1a73e8;\n",
        "    padding: 12px;\n",
        "    margin: 12px 0;\n",
        "    border-radius: 4px;\n",
        "    font-size: 0.95em;\n",
        "}\n",
        "\n",
        "h2 {\n",
        "    color: #1a73e8;\n",
        "    font-size: 1.15em;\n",
        "    margin: 0;\n",
        "}\n",
        "\n",
        ".highlight {\n",
        "    color: #1a73e8;\n",
        "    font-weight: 600;\n",
        "}\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "<div class=\"section-header\">\n",
        "    <h2>📊 Loading CSV Data in LangChain</h2>\n",
        "</div>\n",
        "\n",
        "<div class=\"intro-box\">\n",
        "    <p style=\"margin: 0;\">LangChain's <span class=\"highlight\">CSVLoader</span> enables seamless integration of structured tabular data into RAG systems. This capability transforms spreadsheet data into searchable documents, allowing natural language queries against datasets containing sales records, inventory, research data, or any information organized in rows and columns.</p>\n",
        "</div>\n",
        "\n",
        "<div style=\"background: white; border: 1px solid #dadce0; padding: 20px; border-radius: 6px; margin: 16px 0;\">\n",
        "    <h3 style=\"color: #1a73e8; font-size: 1em; margin: 0 0 10px 0;\">📊 CSV Data Loading</h3>\n",
        "    <p style=\"margin: 0 0 8px 0; font-size: 0.9em;\">Process structured tabular data for analysis and question-answering. The CSVLoader converts each row into a document, preserving column relationships while enabling semantic search across your datasets. This approach bridges the gap between traditional data analysis and natural language processing.</p>\n",
        "    <p style=\"margin: 8px 0 0 0; font-size: 0.85em; color: #666;\"><strong>Common use cases:</strong> Sales and financial data, product catalogs, customer records, survey responses, scientific datasets, inventory management, performance metrics</p>\n",
        "</div>\n",
        "\n",
        "<div style=\"background-color: #f8f9fa; padding: 12px; margin: 16px 0; border-radius: 4px; border: 1px solid #e0e0e0;\">\n",
        "    <p style=\"margin: 0; font-size: 0.9em;\"><strong>💡 Pro Tip:</strong> CSV data maintains its structured nature even after conversion to documents. This allows RAG systems to answer complex questions about trends, comparisons, and aggregations within your tabular data.</p>\n",
        "</div>\n",
        "\n",
        "</body>\n",
        "</html>"
      ],
      "metadata": {
        "id": "7TSID1pEPdQV"
      },
      "id": "7TSID1pEPdQV"
    },
    {
      "cell_type": "code",
      "source": [
        "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "# This cell generates a non-grounded LLM response without using any data source\n",
        "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "# ✅ Initialize LLM\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "# ✅ Query about GDP\n",
        "query = (\n",
        "    \"Compare the GDP of USA, Japan, China, and Qatar in 1980 and 2020. \"\n",
        "    \"For each country, show GDP in 1980, GDP in 2020, and percent change in a concise format, e.g., \"\n",
        "    \"<flag emoji> Country: (1980 → GDP), (2020 → GDP), (% change: #.##%). \"\n",
        "    \"Use billions or trillions of USD, rounded.\"\n",
        ")\n",
        "hallucinated_response = llm.invoke(query).content\n",
        "\n",
        "# ✅ Format and display\n",
        "hallucination_output = f\"\"\"\n",
        "🧠 Hallucinated Response (No RAG):\n",
        "---------------------------------\n",
        "{hallucinated_response}\n",
        "\"\"\"\n",
        "\n",
        "pretty_print(hallucination_output, title=\"🌍 GDP Query without RAG\")\n"
      ],
      "metadata": {
        "id": "XmeE91hiWrUf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "c686804a-39f9-44fe-ead6-cea913268544"
      },
      "id": "XmeE91hiWrUf",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"background-color:#f8f9fc; border-left:5px solid #4285f4;\n",
              "                padding:16px; margin-top:16px; font-family:'Segoe UI', sans-serif;\n",
              "                color:#202124; line-height:1.6;\">\n",
              "      <strong>🌍 GDP Query without RAG</strong><br><br>\n",
              "      <br>🧠 Hallucinated Response (No RAG):<br>---------------------------------<br>🇺🇸 USA: ($2.86 trillion → $21.43 trillion), (% change: 648.95%)<br>🇯🇵 Japan: ($1.12 trillion → $5.08 trillion), (% change: 353.57%)<br>🇨🇳 China: ($0.31 trillion → $14.34 trillion), (% change: 4538.71%)<br>🇶🇦 Qatar: ($6.07 billion → $146.6 billion), (% change: 2314.67%)<br>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6VZH8mO8J7ck"
      },
      "id": "6VZH8mO8J7ck"
    },
    {
      "cell_type": "code",
      "source": [
        "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "#>> RAG RESPONSE (CSV) – GPT-4, One-Line Query, No Prompt Template\n",
        "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.document_loaders import CSVLoader\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# ✅ Step 1: Download CSV from Dropbox\n",
        "csv_url = \"https://www.dropbox.com/scl/fi/nzc5p2gpgb3wja2kf7qdz/GDP_World_Bank.csv?rlkey=jydgntc8jfkm6ajyswovmso3z&st=gwqgc976&dl=1\"\n",
        "with open(\"gdp_data.csv\", \"wb\") as f:\n",
        "    f.write(requests.get(csv_url).content)\n",
        "\n",
        "# ✅ Step 2: Load CSV\n",
        "try:\n",
        "    loader = CSVLoader(\n",
        "        file_path=\"gdp_data.csv\",\n",
        "        encoding=\"utf-8\",\n",
        "        csv_args={\n",
        "            'delimiter': ',',\n",
        "            'quotechar': '\"',\n",
        "            'fieldnames': None\n",
        "        }\n",
        "    )\n",
        "    docs = loader.load()\n",
        "except Exception as e:\n",
        "    print(f\"Error loading CSV: {e}\")\n",
        "    df = pd.read_csv(\"gdp_data.csv\")\n",
        "    from langchain.schema import Document\n",
        "    docs = []\n",
        "    for idx, row in df.iterrows():\n",
        "        content = f\"Country: {row.get('Country Name', 'Unknown')}, \"\n",
        "        for col in df.columns:\n",
        "            if col not in ['Country Name', 'Country Code']:\n",
        "                content += f\"{col}: {row.get(col, 'N/A')}, \"\n",
        "        docs.append(Document(page_content=content, metadata={\"row\": idx}))\n",
        "\n",
        "# ✅ Step 3: Optional - Split documents\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "split_docs = text_splitter.split_documents(docs)\n",
        "\n",
        "# ✅ Step 4: Embedding and vector store\n",
        "embedding = OpenAIEmbeddings()\n",
        "vector_db = FAISS.from_documents(split_docs if split_docs else docs, embedding)\n",
        "\n",
        "# ✅ Step 5: Retriever setup\n",
        "retriever = vector_db.as_retriever(\n",
        "    search_type=\"similarity\",\n",
        "    search_kwargs={\n",
        "        \"k\": 10,\n",
        "        \"score_threshold\": 0.5\n",
        "    }\n",
        ")\n",
        "\n",
        "# ✅ Step 6: RAG chain with no template\n",
        "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
        "rag_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True\n",
        ")\n",
        "\n",
        "# ✅ Step 7: Simple one-line query\n",
        "# ✅ Query about GDP\n",
        "query = (\n",
        "    \"Compare the GDP of China, Japan, China, and Qatar in 1980 and 2020. \"\n",
        "    \"For each country, show GDP in 1980, GDP in 2020, and percent change in a concise format, e.g., \"\n",
        "    \"<flag emoji> Country: (1980 → GDP), (2020 → GDP), (% change: #.##%). \"\n",
        "    \"Use billions or trillions of USD, rounded.\"\n",
        ")\n",
        "\n",
        "\n",
        "rag_response = rag_chain.invoke({\"query\": query})\n",
        "\n",
        "# ✅ Step 8: Display result\n",
        "rag_output = f\"\"\"\n",
        "Retrieval Status: {len(split_docs if 'split_docs' in locals() else docs)} documents in vector store\n",
        "\n",
        "📊 RAG-Based Response (Using CSV):\n",
        "---------------------------------\n",
        "{rag_response['result']}\n",
        "\n",
        "Source Documents Used: {len(rag_response['source_documents'])}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "pretty_print(rag_output, title=\"🌍 GDP Query with CSV-RAG (Simple Query)\")\n"
      ],
      "metadata": {
        "id": "cgIHcYRiY4Rl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "outputId": "71025eaf-354e-4d3d-c4b7-ed5694ea5392"
      },
      "id": "cgIHcYRiY4Rl",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-95c3239bb7a2>:48: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
            "  embedding = OpenAIEmbeddings()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"background-color:#f8f9fc; border-left:5px solid #4285f4;\n",
              "                padding:16px; margin-top:16px; font-family:'Segoe UI', sans-serif;\n",
              "                color:#202124; line-height:1.6;\">\n",
              "      <strong>🌍 GDP Query with CSV-RAG (Simple Query)</strong><br><br>\n",
              "      <br>Retrieval Status: 266 documents in vector store<br><br>📊 RAG-Based Response (Using CSV):<br>---------------------------------<br>🇨🇳 China: (1980 → $191 billion), (2020 → $14.7 trillion), (% change: 7594.24%)<br>🇯🇵 Japan: (1980 → $1.13 trillion), (2020 → $5.06 trillion), (% change: 347.79%)<br>🇨🇳 China: (1980 → $191 billion), (2020 → $14.7 trillion), (% change: 7594.24%)<br>🇶🇦 Qatar: (1980 → $7.83 billion), (2020 → $144 billion), (% change: 1738.44%)<br><br>Source Documents Used: 10<br><br>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "<style>\n",
        "body {\n",
        "    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;\n",
        "    line-height: 1.4;\n",
        "    color: #1a1a1a;\n",
        "    max-width: 750px;\n",
        "    margin: 0 auto;\n",
        "    padding: 8px;\n",
        "    font-size: 14px;\n",
        "}\n",
        "\n",
        ".section-header {\n",
        "    background-color: #e8f0fe;\n",
        "    padding: 12px;\n",
        "    margin: 12px 0;\n",
        "    border-radius: 4px;\n",
        "    border-left: 3px solid #1a73e8;\n",
        "}\n",
        "\n",
        ".intro-box {\n",
        "    background-color: #f0f6ff;\n",
        "    border-left: 3px solid #1a73e8;\n",
        "    padding: 12px;\n",
        "    margin: 12px 0;\n",
        "    border-radius: 4px;\n",
        "    font-size: 0.95em;\n",
        "}\n",
        "\n",
        ".data-type-grid {\n",
        "    display: grid;\n",
        "    grid-template-columns: repeat(2, 1fr);\n",
        "    gap: 16px;\n",
        "    margin: 16px 0;\n",
        "}\n",
        "\n",
        ".data-card {\n",
        "    background: white;\n",
        "    border: 1px solid #dadce0;\n",
        "    padding: 16px;\n",
        "    border-radius: 6px;\n",
        "    border-top: 3px solid #1a73e8;\n",
        "}\n",
        "\n",
        ".code-example {\n",
        "    background-color: #f5f5f5;\n",
        "    border: 1px solid #ddd;\n",
        "    border-radius: 4px;\n",
        "    padding: 12px;\n",
        "    margin: 10px 0;\n",
        "    font-family: 'Courier New', monospace;\n",
        "    font-size: 0.85em;\n",
        "    overflow-x: auto;\n",
        "}\n",
        "\n",
        "h2 {\n",
        "    color: #1a73e8;\n",
        "    font-size: 1.15em;\n",
        "    margin: 0;\n",
        "}\n",
        "\n",
        "h3 {\n",
        "    color: #1a73e8;\n",
        "    font-size: 1em;\n",
        "    margin: 0 0 8px 0;\n",
        "}\n",
        "\n",
        ".highlight {\n",
        "    color: #1a73e8;\n",
        "    font-weight: 600;\n",
        "}\n",
        "\n",
        ".use-case-list {\n",
        "    margin: 8px 0;\n",
        "    padding-left: 20px;\n",
        "    font-size: 0.9em;\n",
        "}\n",
        "\n",
        ".use-case-list li {\n",
        "    margin: 4px 0;\n",
        "    color: #555;\n",
        "}\n",
        "\n",
        ".chart-container {\n",
        "    background: white;\n",
        "    border: 1px solid #dadce0;\n",
        "    padding: 16px;\n",
        "    border-radius: 6px;\n",
        "    margin: 16px 0;\n",
        "    text-align: center;\n",
        "}\n",
        "\n",
        ".chart-container img {\n",
        "    max-width: 70%;\n",
        "    height: auto;\n",
        "    border-radius: 4px;\n",
        "}\n",
        "\n",
        ".question-box {\n",
        "    background-color: #fff3cd;\n",
        "    border-left: 3px solid #ffc107;\n",
        "    padding: 12px;\n",
        "    margin: 16px 0;\n",
        "    border-radius: 4px;\n",
        "}\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "<div class=\"section-header\">\n",
        "    <h2>📊 World Bank GDP Data Analysis</h2>\n",
        "</div>\n",
        "\n",
        "<div class=\"intro-box\">\n",
        "    <p style=\"margin: 0;\">The provided data from the <span class=\"highlight\">World Bank</span> shows the GDP of countries as shown in the image below. This dataset provides valuable insights into global economic indicators and can be used to test the accuracy of <span class=\"highlight\">RAG model implementations</span> when processing economic data.</p>\n",
        "</div>\n",
        "\n",
        "<div class=\"chart-container\">\n",
        "    <img src=\"https://www.dropbox.com/scl/fi/bmitdcpfoqmib886t26vv/GDP_Chart.png?rlkey=1xmwtmvybl7h1rp3dxvbj972m&raw=1\" alt=\"GDP Chart\" style=\"width: 70%; max-width: 70%;\">\n",
        "</div>\n",
        "\n",
        "<div class=\"question-box\">\n",
        "    <h3 style=\"color: #856404; margin: 0;\">❓ Did your RAG model provide accurate values based on this dataset?</h3>\n",
        "</div>\n",
        "\n",
        "</body>\n",
        "</html>\n"
      ],
      "metadata": {
        "id": "VX0mSQR6knhP"
      },
      "id": "VX0mSQR6knhP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "<style>\n",
        "body {\n",
        "    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;\n",
        "    line-height: 1.4;\n",
        "    color: #1a1a1a;\n",
        "    max-width: 750px;\n",
        "    margin: 0 auto;\n",
        "    padding: 8px;\n",
        "    font-size: 14px;\n",
        "}\n",
        "\n",
        ".section-header {\n",
        "    background-color: #e8f0fe;\n",
        "    padding: 12px;\n",
        "    margin: 12px 0;\n",
        "    border-radius: 4px;\n",
        "    border-left: 3px solid #1a73e8;\n",
        "}\n",
        "\n",
        ".intro-box {\n",
        "    background-color: #f0f6ff;\n",
        "    border-left: 3px solid #1a73e8;\n",
        "    padding: 12px;\n",
        "    margin: 12px 0;\n",
        "    border-radius: 4px;\n",
        "    font-size: 0.95em;\n",
        "}\n",
        "\n",
        ".data-type-grid {\n",
        "    display: grid;\n",
        "    grid-template-columns: repeat(2, 1fr);\n",
        "    gap: 16px;\n",
        "    margin: 16px 0;\n",
        "}\n",
        "\n",
        ".data-card {\n",
        "    background: white;\n",
        "    border: 1px solid #dadce0;\n",
        "    padding: 16px;\n",
        "    border-radius: 6px;\n",
        "    border-top: 3px solid #1a73e8;\n",
        "}\n",
        "\n",
        ".code-example {\n",
        "    background-color: #f5f5f5;\n",
        "    border: 1px solid #ddd;\n",
        "    border-radius: 4px;\n",
        "    padding: 12px;\n",
        "    margin: 10px 0;\n",
        "    font-family: 'Courier New', monospace;\n",
        "    font-size: 0.85em;\n",
        "    overflow-x: auto;\n",
        "}\n",
        "\n",
        "h2 {\n",
        "    color: #1a73e8;\n",
        "    font-size: 1.15em;\n",
        "    margin: 0;\n",
        "}\n",
        "\n",
        "h3 {\n",
        "    color: #1a73e8;\n",
        "    font-size: 1em;\n",
        "    margin: 0 0 8px 0;\n",
        "}\n",
        "\n",
        ".highlight {\n",
        "    color: #1a73e8;\n",
        "    font-weight: 600;\n",
        "}\n",
        "\n",
        ".use-case-list {\n",
        "    margin: 8px 0;\n",
        "    padding-left: 20px;\n",
        "    font-size: 0.9em;\n",
        "}\n",
        "\n",
        ".use-case-list li {\n",
        "    margin: 4px 0;\n",
        "    color: #555;\n",
        "}\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "<div class=\"section-header\">\n",
        "    <h2>🔷 Loading External Data: HTML & CSV in LangChain</h2>\n",
        "</div>\n",
        "\n",
        "<div class=\"intro-box\">\n",
        "    <p style=\"margin: 0;\">LangChain extends beyond PDF processing to support diverse data sources. <span class=\"highlight\">HTML loaders</span> enable web content ingestion for real-time information retrieval, while <span class=\"highlight\">CSV loaders</span> handle structured data analysis. These capabilities allow RAG systems to work with dynamic web content and tabular datasets alongside traditional documents.</p>\n",
        "</div>\n",
        "\n",
        "<div style=\"background: white; border: 1px solid #dadce0; padding: 20px; border-radius: 6px; margin: 16px 0;\">\n",
        "    <h3 style=\"color: #1a73e8; font-size: 1em; margin: 0 0 10px 0;\">🌐 HTML Data Loading</h3>\n",
        "    <p style=\"margin: 0 0 8px 0; font-size: 0.9em;\">Extract content from web pages for up-to-date information retrieval. Perfect for incorporating current events, documentation, or any web-based content into your RAG system. LangChain's HTML loaders enable seamless integration of web content into your document processing pipeline.</p>\n",
        "    <p style=\"margin: 8px 0 0 0; font-size: 0.85em; color: #666;\"><strong>Common use cases:</strong> News articles and blog posts, technical documentation, Wikipedia entries, company websites, product pages, FAQ sections</p>\n",
        "</div>\n",
        "\n",
        "<div style=\"background-color: #f8f9fa; padding: 12px; margin: 16px 0; border-radius: 4px; border: 1px solid #e0e0e0;\">\n",
        "    <p style=\"margin: 0; font-size: 0.9em;\"><strong>💡 Pro Tip:</strong> Both loaders convert content into LangChain Document objects, maintaining consistency across different data sources. This allows you to apply the same embedding and retrieval pipeline regardless of whether your source is a PDF, web page, or CSV file.</p>\n",
        "</div>\n",
        "\n",
        "</body>\n",
        "</html>"
      ],
      "metadata": {
        "id": "cTX-PTnGAtwj"
      },
      "id": "cTX-PTnGAtwj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ✋**Hands-On: RAG with HTML Data**\n",
        "\n",
        "---\n",
        "\n",
        "## 🌐 Load HTML from a Webpage or Local File\n",
        "\n",
        "```python\n",
        "from langchain.document_loaders import HTMLLoader\n",
        "\n",
        "# Load from a webpage\n",
        "html_loader = HTMLLoader(\"https://en.wikipedia.org/wiki/Artificial_intelligence\")\n",
        "html_docs = html_loader.load()\n",
        "\n",
        "# OR load from a local file\n",
        "# html_loader = HTMLLoader(\"data/my_page.html\")\n",
        "# html_docs = html_loader.load()\n"
      ],
      "metadata": {
        "id": "jS5bBlCKjE4H"
      },
      "id": "jS5bBlCKjE4H"
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================\n",
        "# ✋ **Hands-On: Load & Retrieve Renewable Energy Info from Wikipedia**\n",
        "# ==================================================\n",
        "# 📌 **Task Instructions:**\n",
        "# 1️⃣ Fill in the missing placeholders (`-----`) to complete the process.\n",
        "# 2️⃣ Use `HTMLLoader` to load Wikipedia data.\n",
        "# 3️⃣ Split text into retrievable chunks.\n",
        "# 4️⃣ Convert chunks into vector embeddings using FAISS.\n",
        "# 5️⃣ Use retrieval to answer a question about renewable energy.\n",
        "\n",
        "# First, let's check if we need to install additional packages\n",
        "# !pip install langchain langchain-community langchain-openai faiss-cpu beautifulsoup4 lxml\n",
        "\n",
        "# Updated imports for newer LangChain versions\n",
        "from langchain_community.document_loaders import UnstructuredHTMLLoader, UnstructuredURLLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_openai import OpenAI\n",
        "\n",
        "# Alternative: If you need to use WebBaseLoader for web content\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "# ==================================================\n",
        "# ✅ Step 1: Load Wikipedia Page on Renewable Energy\n",
        "# ==================================================\n",
        "wiki_url = \"https://en.wikipedia.org/wiki/World_War_II\"\n",
        "\n",
        "# Option 1: Using WebBaseLoader (recommended for web content)\n",
        "loader = WebBaseLoader(wiki_url)  # Load HTML from Wikipedia\n",
        "documents = loader.load()  # Extract text from the page\n",
        "\n",
        "# Option 2: Using UnstructuredURLLoader (if WebBaseLoader doesn't work)\n",
        "# loader = UnstructuredURLLoader(urls=[wiki_url])\n",
        "# documents = loader.load()\n",
        "\n",
        "# ==================================================\n",
        "# ✅ Step 2: Split Text into Chunks\n",
        "# ==================================================\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "docs = text_splitter.split_documents(documents)  # Split extracted text into smaller chunks\n",
        "\n",
        "# ==================================================\n",
        "# ✅ Step 3: Convert Chunks to Embeddings & Store in FAISS\n",
        "# ==================================================\n",
        "embedding_model = OpenAIEmbeddings()  # Use OpenAIEmbeddings\n",
        "vector_db = FAISS.from_documents(docs, embedding_model)  # Convert docs into vector embeddings and store in FAISS\n",
        "\n",
        "# ==================================================\n",
        "# ✅ Step 4: Create a Retriever to Fetch Relevant Information\n",
        "# ==================================================\n",
        "retriever = vector_db.as_retriever()  # Convert FAISS vector store into a retriever\n",
        "\n",
        "# ==================================================\n",
        "# ✅ Step 5: Ask AI a Question About Renewable Energy\n",
        "# ==================================================\n",
        "llm = OpenAI()  # Initialize the language model\n",
        "rag_chain = RetrievalQA.from_chain_type(llm, retriever=retriever)  # Define the RAG pipeline\n",
        "\n",
        "query = \"Which coutires fought in world war 2?\"\n",
        "response_rag = rag_chain.run(query)\n",
        "\n",
        "# ✅ Step 6: Display Retrieved Answer\n",
        "print(\"\\n🌍 🔋 AI Answer on world war 2:\")\n",
        "print(response_rag)\n",
        "\n",
        "# ==================================================\n",
        "# 💡 Extended Lab: Additional Queries and Analysis\n",
        "# ==================================================\n",
        "\n",
        "# Additional queries to explore different aspects of renewable energy\n",
        "additional_queries = [\n",
        "     \"What factors led to world war 2 \",\n",
        "    \"what was the aftermath of world war 2?\",\n",
        "    \"What happend in Japan during that time\"\n",
        "\n",
        "]\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"📊 Additional World War 2 Insights:\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "for i, query in enumerate(additional_queries, 1):\n",
        "    print(f\"\\n❓ Question {i}: {query}\")\n",
        "    response = rag_chain.run(query)\n",
        "    print(f\"💡 Answer: {response}\")\n",
        "\n",
        "# ==================================================\n",
        "# 🔧 Alternative Embeddings Extension\n",
        "# ==================================================\n",
        "# You can extend this lab by using different embedding models:\n",
        "\n",
        "# Option 1: Using HuggingFace Embeddings\n",
        "# from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "# embedding_model_hf = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "# vector_db_hf = FAISS.from_documents(docs, embedding_model_hf)\n",
        "\n",
        "# Option 2: Using Cohere Embeddings\n",
        "# from langchain_community.embeddings import CohereEmbeddings\n",
        "# embedding_model_cohere = CohereEmbeddings(cohere_api_key=\"your-api-key\")\n",
        "# vector_db_cohere = FAISS.from_documents(docs, embedding_model_cohere)\n",
        "\n",
        "# ==================================================\n",
        "# 🎯 Vector Settings Extension\n",
        "# ==================================================\n",
        "# You can experiment with different vector store settings:\n",
        "\n",
        "# 1. Adjust retriever settings for better results\n",
        "retriever_custom = vector_db.as_retriever(\n",
        "    search_type=\"similarity\",  # or \"mmr\" for Maximum Marginal Relevance\n",
        "    search_kwargs={\"k\": 4}  # Retrieve top 4 most relevant chunks\n",
        ")\n",
        "\n",
        "# 2. Use similarity search with score threshold\n",
        "retriever_threshold = vector_db.as_retriever(\n",
        "    search_type=\"similarity_score_threshold\",\n",
        "    search_kwargs={\"score_threshold\": 0.5, \"k\": 3}\n",
        ")\n",
        "\n",
        "# 3. Test different chunk sizes for optimal retrieval\n",
        "text_splitter_large = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=100\n",
        ")\n",
        "docs_large = text_splitter_large.split_documents(documents)\n",
        "\n",
        "# ==================================================\n",
        "# 📈 Performance Comparison\n",
        "# ==================================================\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"🔍 Testing Different Retrieval Settings:\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "test_query = \"\"\n",
        "\n",
        "# Test with custom retriever\n",
        "rag_chain_custom = RetrievalQA.from_chain_type(llm, retriever=retriever_custom)\n",
        "response_custom = rag_chain_custom.run(test_query)\n",
        "print(f\"\\n🎯 Custom Retriever (k=4):\")\n",
        "print(response_custom)\n",
        "\n",
        "# Test with threshold-based retriever\n",
        "rag_chain_threshold = RetrievalQA.from_chain_type(llm, retriever=retriever_threshold)\n",
        "response_threshold = rag_chain_threshold.run(test_query)\n",
        "print(f\"\\n📊 Threshold Retriever (score > 0.5):\")\n",
        "print(response_threshold)\n"
      ],
      "metadata": {
        "id": "wMfwf0xUz1Zq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09fb0af2-26f1-408a-ccee-f3c8788e3715"
      },
      "id": "wMfwf0xUz1Zq",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🌍 🔋 AI Answer on world war 2:\n",
            " A lot of countries fought in World War II, including Germany, Italy, Japan, France, the Soviet Union, the United States, Canada, and many others. The list of countries involved is extensive and can vary depending on the specific time period and location being referred to.\n",
            "\n",
            "==================================================\n",
            "📊 Additional World War 2 Insights:\n",
            "==================================================\n",
            "\n",
            "❓ Question 1: What factors led to world war 2 \n",
            "💡 Answer:  The unresolved tensions from World War I, the rise of fascism in Europe and militarism in Japan, Japan's invasion of Manchuria, the Spanish Civil War, the outbreak of the Second Sino-Japanese War, and Germany's annexations of Austria and the Sudetenland all contributed to the start of World War II. Additionally, the failure of the League of Nations to prevent aggression and the appeasement policies of Western powers also played a role.\n",
            "\n",
            "❓ Question 2: what was the aftermath of world war 2?\n",
            "💡 Answer:  The aftermath of World War II included the prosecution of prominent members of Nazi Germany, the emergence of the United States as a dominant economic power, the beginning of the Cold War between the Soviet Union and the US, and the decolonisation of Africa and Asia.\n",
            "\n",
            "❓ Question 3: What happend in Japan during that time\n",
            "💡 Answer:  During that time, Japan experienced deteriorating relations with the United States due to various incidents, such as the Mukden incident and the Nanjing Massacre. As a result, the United States implemented economic sanctions against Japan. Japan also faced tensions with the Soviet Union and had a policy of expansion northward, which was challenged by their defeat at Khalkin Gol and Nazi Germany's pursuit of neutrality with the Soviets. Emperor Hirohito eventually favored Japan's entry into war, leading to Prime Minister Fumimaro Konoe's resignation and the appointment of War Minister Hideki Tojo.\n",
            "\n",
            "==================================================\n",
            "🔍 Testing Different Retrieval Settings:\n",
            "==================================================\n",
            "\n",
            "🎯 Custom Retriever (k=4):\n",
            " I don't know.\n",
            "\n",
            "📊 Threshold Retriever (score > 0.5):\n",
            " I don't know.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================\n",
        "# 🟢 FULL NOTEBOOK ─ Renewable-Energy RAG with ChromaDB\n",
        "# ==================================================\n",
        "# 1) Installs  •  2) Load Wikipedia page  •  3) Chunk text\n",
        "# 4) Embed chunks via OpenAI  •  5) Store in ChromaDB\n",
        "# 6) Ask questions with Retrieval-QA\n",
        "# --------------------------------------------------\n",
        "# ‼️ Run each cell top-to-bottom in Google Colab (or locally)\n",
        "# ==================================================\n",
        "\n",
        "# ╔════════════════════════════════════════════════════════════════╗\n",
        "# ║ 1️⃣  INSTALL DEPENDENCIES                                      ║\n",
        "# ╚════════════════════════════════════════════════════════════════╝\n",
        "!pip install -q \\\n",
        "    langchain langchain-community langchain-openai \\\n",
        "    chromadb beautifulsoup4 lxml\n",
        "\n",
        "# ╔════════════════════════════════════════════════════════════════╗\n",
        "# ║ 2️⃣  IMPORTS & API-KEY SETUP (Colab secrets or .env)           ║\n",
        "# ╚════════════════════════════════════════════════════════════════╝\n",
        "import os\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings, OpenAI\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# --- Colab secret (name = openAI_apikey) -------\n",
        "try:\n",
        "    from google.colab import userdata          # ignore if running locally\n",
        "    os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"openAI_apikey\", \"\")\n",
        "except Exception:\n",
        "    # fallback to .env or manual export\n",
        "    pass\n",
        "\n",
        "assert os.getenv(\"OPENAI_API_KEY\"), \"🔑 Add your OpenAI key first!\"\n",
        "\n",
        "# ╔════════════════════════════════════════════════════════════════╗\n",
        "# ║ 3️⃣  LOAD WIKIPEDIA PAGE (Renewable Energy)                    ║\n",
        "# ╚════════════════════════════════════════════════════════════════╝\n",
        "wiki_url = \"https://en.wikipedia.org/wiki/World_War_II\"\n",
        "loader = WebBaseLoader(wiki_url)        # simple HTTP fetch + HTML → text\n",
        "documents = loader.load()\n",
        "\n",
        "# ╔════════════════════════════════════════════════════════════════╗\n",
        "# ║ 4️⃣  SPLIT INTO CHUNKS                                         ║\n",
        "# ╚════════════════════════════════════════════════════════════════╝\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "docs = splitter.split_documents(documents)\n",
        "\n",
        "# ╔════════════════════════════════════════════════════════════════╗\n",
        "# ║ 5️⃣  EMBED + STORE IN CHROMADB                                 ║\n",
        "# ╚════════════════════════════════════════════════════════════════╝\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "# ▸ Option A: in-memory (discarded when runtime shuts down)\n",
        "vector_db = Chroma.from_documents(\n",
        "    docs,\n",
        "    embeddings,\n",
        "    collection_name=\"renewable_energy_inmem\"\n",
        ")\n",
        "\n",
        "# ▸ Option B: persistent store (uncomment to keep vectors on disk)\n",
        "# vector_db = Chroma.from_documents(\n",
        "#     docs,\n",
        "#     embeddings,\n",
        "#     collection_name=\"renewable_energy\",\n",
        "#     persist_directory=\"./chroma_store\"\n",
        "# )\n",
        "# vector_db.persist()   # write index to disk\n",
        "\n",
        "retriever = vector_db.as_retriever()\n",
        "\n",
        "# ╔════════════════════════════════════════════════════════════════╗\n",
        "# ║ 6️⃣  BUILD RAG CHAIN & ASK QUESTIONS                           ║\n",
        "# ╚════════════════════════════════════════════════════════════════╝\n",
        "llm = OpenAI()                      # GPT-4o / GPT-4-Turbo depending on key\n",
        "qa_chain = RetrievalQA.from_chain_type(llm, retriever=retriever)\n",
        "\n",
        "# Primary question\n",
        "print(\"🔍 Question: Which coutires fought in world war 2?\\n\")\n",
        "print(\"💡 Answer:\", qa_chain.run(\n",
        "    \"Which coutires fought in world war 2?\"\n",
        "))\n",
        "\n",
        "# Additional exploration\n",
        "extra_qs = [\n",
        "     \"What factors led to world war 2 \",\n",
        "    \"what was the aftermath of world war 2?\",\n",
        "    \"What happend in Japan during that time\"\n",
        "\n",
        "]\n",
        "\n",
        "for q in extra_qs:\n",
        "    print(\"\\n────────────────────────────────────────────\")\n",
        "    print(\"❓\", q)\n",
        "    print(\"💡\", qa_chain.run(q))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESffz5kGCyoo",
        "outputId": "e38446be-0c32-4c76-ae1b-0ea5e96ae032"
      },
      "id": "ESffz5kGCyoo",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Question: Which coutires fought in world war 2?\n",
            "\n",
            "💡 Answer:  The countries that fought in World War 2 are listed in the provided context, including Germany, Italy, France, Russia, and several others. \n",
            "\n",
            "────────────────────────────────────────────\n",
            "❓ What factors led to world war 2 \n",
            "💡  Unresolved tensions from World War I and the rise of fascism in Europe and militarism in Japan, key events such as Japan's invasion of Manchuria, the Spanish Civil War, and Germany's annexations, and the invasion of Poland by Nazi Germany under Adolf Hitler.\n",
            "\n",
            "────────────────────────────────────────────\n",
            "❓ what was the aftermath of world war 2?\n",
            "💡  The aftermath of World War 2 included the prosecution of prominent members of Nazi Germany, the emergence of the Soviet Union and US as global superpowers, and the decolonisation of Africa and Asia. The global economy also suffered, with the United States emerging as the dominant economic power.\n",
            "\n",
            "────────────────────────────────────────────\n",
            "❓ What happend in Japan during that time\n",
            "💡  Japan's relations with the United States deteriorated, leading to economic sanctions and preparation for war. Emperor Hirohito eventually favored Japan's entry into the war and appointed Hideki Tojo as Prime Minister. Japan also had border clashes with the Soviet Union and Mongolia and pursued a policy of expansion northward, but faced difficulties due to defeat at Khalkin Gol and the ongoing Second Sino-Japanese War.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================\n",
        "# 🟢 FULL NOTEBOOK ─ Renewable-Energy RAG\n",
        "#    • Hugging Face Embeddings (local)\n",
        "#    • FAISS Vector Store\n",
        "# ==================================================\n",
        "# 1) Install packages  • 2) Load Wikipedia page\n",
        "# 3) Chunk text        • 4) Embed chunks via HF model\n",
        "# 5) Store vectors in FAISS  • 6) Ask questions with Retrieval-QA\n",
        "# --------------------------------------------------\n",
        "\n",
        "# ╔════════════════════════════════════════════════╗\n",
        "# ║ 1️⃣  INSTALL DEPENDENCIES                      ║\n",
        "# ╚════════════════════════════════════════════════╝\n",
        "!pip install -q \\\n",
        "    langchain langchain-community langchain-openai \\\n",
        "    sentence-transformers faiss-cpu \\\n",
        "    beautifulsoup4 lxml\n",
        "\n",
        "# ╔════════════════════════════════════════════════╗\n",
        "# ║ 2️⃣  IMPORTS                                   ║\n",
        "# ╚════════════════════════════════════════════════╝\n",
        "import os\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings    # ⭐ NEW\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# ╔════════════════════════════════════════════════╗\n",
        "# ║ 3️⃣  LOAD WIKIPEDIA PAGE (Renewable Energy)    ║\n",
        "# ╚════════════════════════════════════════════════╝\n",
        "wiki_url = \"https://en.wikipedia.org/wiki/World_War_II\"\n",
        "documents = WebBaseLoader(wiki_url).load()\n",
        "\n",
        "# ╔════════════════════════════════════════════════╗\n",
        "# ║ 4️⃣  SPLIT INTO CHUNKS                         ║\n",
        "# ╚════════════════════════════════════════════════╝\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "docs     = splitter.split_documents(documents)\n",
        "\n",
        "# ╔════════════════════════════════════════════════╗\n",
        "# ║ 5️⃣  EMBED + STORE IN FAISS                    ║\n",
        "# ╚════════════════════════════════════════════════╝\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",  # tiny, fast\n",
        "    model_kwargs={\"device\": \"cpu\"}                       # change to \"cuda\" if GPU\n",
        ")\n",
        "vector_db  = FAISS.from_documents(docs, embeddings)\n",
        "retriever  = vector_db.as_retriever()\n",
        "\n",
        "# ╔════════════════════════════════════════════════╗\n",
        "# ║ 6️⃣  BUILD RAG CHAIN & ASK QUESTIONS           ║\n",
        "# ╚════════════════════════════════════════════════╝\n",
        "llm      = OpenAI()                       # still GPT-4 / GPT-4o for answers\n",
        "qa_chain = RetrievalQA.from_chain_type(llm, retriever=retriever)\n",
        "\n",
        "print(\"🔍 Question: Which coutires fought in world war 2? \\n\")\n",
        "print(\"💡 Answer:\", qa_chain.run(\n",
        "    \"Which coutires fought in world war 2?\"\n",
        "))\n",
        "\n",
        "# ── Extra exploration ───────────────────────────────\n",
        "extra_qs = [\n",
        "    \"What factors led to world war 2 \",\n",
        "    \"what was the aftermath of world war 2?\",\n",
        "    \"What happend in Japan during that time\"\n",
        "\n",
        "]\n",
        "\n",
        "for q in extra_qs:\n",
        "    print(\"\\n────────────────────────────────────────────\")\n",
        "    print(\"❓\", q)\n",
        "    print(\"💡\", qa_chain.run(q))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIEM2zQ8EaIt",
        "outputId": "e60d0bd1-0c3f-459a-8429-3772b99eef92"
      },
      "id": "vIEM2zQ8EaIt",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Question: Which coutires fought in world war 2? \n",
            "\n",
            "💡 Answer:  Nearly all of the world's countries participated in World War II, with many nations mobilizing all resources in pursuit of total war. Some specific countries that were involved include Germany, Italy, Japan, the United States, the Soviet Union, France, and the United Kingdom.\n",
            "\n",
            "────────────────────────────────────────────\n",
            "❓ What factors led to world war 2 \n",
            "💡  The causes of World War II included unresolved tensions in the aftermath of World War I, the rise of fascism in Europe and militarism in Japan, and key events such as Japan's invasion of Manchuria, the Spanish Civil War, and Germany's annexations of Austria and the Sudetenland. The invasion of Poland by Nazi Germany is generally considered the starting point of the war.\n",
            "\n",
            "────────────────────────────────────────────\n",
            "❓ what was the aftermath of world war 2?\n",
            "💡  The aftermath of World War II included the formation of the United Nations, the division of Germany into East and West, and the beginning of the Cold War between the United States and Soviet Union. It also led to major changes in global politics, borders, and international relations.\n",
            "\n",
            "────────────────────────────────────────────\n",
            "❓ What happend in Japan during that time\n",
            "💡  During this time, Japan's economy was being strangled by a naval blockade and they were facing a stalemate in their war with China. Japan also invaded and occupied northern China to block supply routes and better position themselves for a potential war with Western powers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "<style>\n",
        "body {\n",
        "    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;\n",
        "    line-height: 1.4;\n",
        "    color: #1a1a1a;\n",
        "    max-width: 750px;\n",
        "    margin: 0 auto;\n",
        "    padding: 8px;\n",
        "    font-size: 14px;\n",
        "}\n",
        ".section-header {\n",
        "    background-color: #e8f0fe;\n",
        "    padding: 12px;\n",
        "    margin: 12px 0;\n",
        "    border-radius: 4px;\n",
        "    border-left: 3px solid #1a73e8;\n",
        "}\n",
        ".intro-box {\n",
        "    background-color: #f0f6ff;\n",
        "    border-left: 3px solid #1a73e8;\n",
        "    padding: 12px;\n",
        "    margin: 12px 0;\n",
        "    border-radius: 4px;\n",
        "    font-size: 0.95em;\n",
        "}\n",
        "h1 {\n",
        "    color: #1a73e8;\n",
        "    font-size: 1.5em;\n",
        "    text-align: center;\n",
        "    margin: 20px 0;\n",
        "}\n",
        "h2 {\n",
        "    color: #1a73e8;\n",
        "    font-size: 1.15em;\n",
        "    margin: 0;\n",
        "}\n",
        ".highlight {\n",
        "    color: #1a73e8;\n",
        "    font-weight: 600;\n",
        "}\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "<h1>🎉 Congratulations!</h1>\n",
        "\n",
        "<div class=\"section-header\">\n",
        "    <h2>✅ Lab Completed: RAG with LangChain & FAISS</h2>\n",
        "</div>\n",
        "\n",
        "<div class=\"intro-box\">\n",
        "    <p style=\"margin: 0 0 12px 0;\">You successfully integrated <span class=\"highlight\">LangChain</span> with <span class=\"highlight\">FAISS</span> to build a RAG pipeline for World Bank GDP data. Great job mastering vector databases and semantic search!</p>\n",
        "    <p style=\"margin: 0;\">❓ You need to extend this lab based on other embeddings or/and vector settings. Check Canvas and lab requirements for more details.</p>\n",
        "</div>\n",
        "\n",
        "</body>\n",
        "</html>"
      ],
      "metadata": {
        "id": "IAK9Pn5U6_6c"
      },
      "id": "IAK9Pn5U6_6c"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}